{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier=load_model('model/12_facenet_keras1_6-2-20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir = 'faces/train'\n",
    "imageSize=160\n",
    "batchSize=1000\n",
    "\n",
    "train_datagen=ImageDataGenerator( rescale=1./255,\n",
    "                                  rotation_range=45,\n",
    "                                  width_shift_range=0.3,\n",
    "                                  height_shift_range=0.3,\n",
    "                                  horizontal_flip=True,\n",
    "                                  fill_mode='nearest'\n",
    "                                ) \n",
    "train_generator=train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                  target_size=(imageSize,imageSize),\n",
    "                                                  color_mode='rgb',\n",
    "                                                  batch_size=batchSize,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=True\n",
    "                                                  )\n",
    "\n",
    "\n",
    "class_labels = train_generator.class_indices\n",
    "person_dict = {v: k for k, v in class_labels.items()}\n",
    "classes = list(person_dict.values())\n",
    "print(person_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# person_dict={'[0]': 'Amrender', '[1]': 'Anshika', '[2]': 'Arvind', '[3]': 'Ashmita', '[4]': 'Bhanu', '[5]': 'Shweta', '[6]': 'Sonmati'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ####  By Webcam ####\n",
    "\n",
    "# face_cascade = r\"C:\\Users\\Amrender\\Downloads\\Realtime Face Recognition with DL Working\\haarcascade_frontalface_alt.xml\"\n",
    "# cascade = cv2.CascadeClassifier(face_cascade)\n",
    "# IMAGE_SIZE=160\n",
    "# url='https://192.168.43.1:8080/video'\n",
    "# camera = cv2.VideoCapture(0)\n",
    "\n",
    "# while True:\n",
    "    \n",
    "#     ret, frame = camera.read()\n",
    "#     frame = imutils.resize(frame, width = 800, height = 600)\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#     faceRects=cascade.detectMultiScale(gray,scaleFactor=1.3,minNeighbors=5)\n",
    "    \n",
    "#     for (x, y, w, h) in faceRects:\n",
    "        \n",
    "#         roi = frame[y:y+h,x:x+w]\n",
    "#         roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "#         roi = cv2.resize(roi,(IMAGE_SIZE, IMAGE_SIZE))\n",
    "#         roi = roi / 255.\n",
    "#         roi = roi.reshape(1,IMAGE_SIZE,IMAGE_SIZE,3)\n",
    "#         result = classifier.predict(roi, 1, verbose = 0).argmax()\n",
    "#         person = person_dict[result]\n",
    "#         print(person) \n",
    "# #         result = np.argmax(classifier.predict(roi, 1, verbose = 0), axis=1)\n",
    "# #         print(result)\n",
    "# #         person = person_dict[str(result)]\n",
    "#         cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "#         cv2.putText(frame, person, (x+ (w//2),y-2), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), lineType=cv2.LINE_AA)\n",
    "\n",
    "# #         else:\n",
    "# #             person = 'Unknown '\n",
    "# #             print(person) \n",
    "# #             cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "# #             cv2.putText(frame, person, (x+ (w//2),y-2), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), lineType=cv2.LINE_AA)\n",
    "    \n",
    "#     cv2.imshow('frame', frame)\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# camera.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# from os import listdir\n",
    "# from tensorflow.keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "# from tensorflow.python.keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "# def preprocess_image(image_path):\n",
    "#     img = load_img(image_path, target_size=(160, 160))\n",
    "#     img = img_to_array(img)\n",
    "#     img = img / 255.\n",
    "#     img = img.reshape(1,160,160,3) \n",
    "#     return img\n",
    "\n",
    "# people_pictures = \"./persons/\"\n",
    "\n",
    "# all_people_faces = dict()\n",
    "\n",
    "# for file in listdir(people_pictures):\n",
    "#     person_face, extension = file.split(\".\")\n",
    "#     all_people_faces[person_face] = classifier.predict(preprocess_image('persons/%s.png' % (person_face)))[0,:]\n",
    "# #     all_people_faces[person_face] = classifier.predict(preprocess_image('persons/%s.png' % (person_face))).argmax()\n",
    "# #     print(person_face,all_people_faces[person_face],person_dict[all_people_faces[person_face]])\n",
    "    \n",
    "\n",
    "# def findCosineSimilarity(source_representation, test_representation):\n",
    "#     a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "#     b = np.sum(np.multiply(source_representation, source_representation))\n",
    "#     c = np.sum(np.multiply(test_representation, test_representation))\n",
    "#     return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "\n",
    "# input_im=cv2.imread(\"testImages/abc8.jpg\")\n",
    "# input_im = imutils.resize(input_im, width = 800)\n",
    "# face_cascade = \"haarcascade_frontalface_default.xml\"\n",
    "# cascade = cv2.CascadeClassifier(face_cascade)\n",
    "# faces=cascade.detectMultiScale(input_im,1.3,5)\n",
    "# print(len(faces))\n",
    "\n",
    "# for i in range(len(faces)):\n",
    "#     x,y,w,h=faces[i]\n",
    "#     sub_face = input_im[y:y + h, x:x + w,:]\n",
    "    \n",
    "#     sub_face = cv2.resize(sub_face, (160, 160), interpolation = cv2.INTER_LINEAR)\n",
    "#     sub_face = sub_face / 255.\n",
    "#     sub_face = sub_face.reshape(1,160,160,3) \n",
    "#     captured_representation = classifier.predict(sub_face)[0,:]\n",
    "#     found = 0\n",
    "#     for i in all_people_faces:\n",
    "#         person_name = i\n",
    "#         representation = all_people_faces[i]\n",
    "#         similarity = findCosineSimilarity(representation, captured_representation)\n",
    "#         if(similarity < 0.30):\n",
    "#             cv2.putText(input_im, person_name, (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "#             found = 1\n",
    "#             break\n",
    "#     #connect face and text\n",
    "#     cv2.line(input_im,(int((x+x+w)/2),y+15),(x+w,y-20),(255, 0, 0),1)\n",
    "#     cv2.line(input_im,(x+w,y-20),(x+w+10,y-20),(255, 0, 0),1)\n",
    "\n",
    "#     if(found == 0): #if found image is not in our people database\n",
    "#         cv2.putText(input_im, 'unknown', (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "# cv2.imshow('img',input_im)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from os import listdir\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "# detector=MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.test.is_built_with_cuda()\n",
    "# tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = [ 0.6, 0.7, 0.7 ] \n",
    "detector=MTCNN(min_face_size=20,scale_factor=.709, steps_threshold = threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_image(image_path):\n",
    "#     img = load_img(image_path, target_size=(160, 160))\n",
    "#     img = img_to_array(img)\n",
    "#     img = img / 255.\n",
    "#     img = img.reshape(1,160,160,3) \n",
    "#     return img\n",
    "\n",
    "# people_pictures = \"./persons/\"\n",
    "# # imageName='new.jpg'\n",
    "\n",
    "# all_people_faces = dict()\n",
    "\n",
    "# for file in listdir(people_pictures):\n",
    "#     person_face, extension = file.split(\".\")\n",
    "#     all_people_faces[person_face] = classifier.predict(preprocess_image('persons/%s.png' % (person_face)))[0,:]\n",
    "# #     print(person_face, all_people_faces[person_face])\n",
    "# #     all_people_faces[person_face] = classifier.predict(preprocess_image('persons/%s.png' % (person_face)))[0,:].argmax()\n",
    "# #     print(person_face,all_people_faces[person_face],person_dict[all_people_faces[person_face]])\n",
    "# print('------------------------------------------------------------------------------------------------')    \n",
    "\n",
    "# def findCosineSimilarity(source_representation, test_representation):\n",
    "#     a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "#     b = np.sum(np.multiply(source_representation, source_representation))\n",
    "#     c = np.sum(np.multiply(test_representation, test_representation))\n",
    "#     return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "\n",
    "\n",
    "# # image=cv2.imread(\"testImages/abca.jpg\",1)\n",
    "# image=cv2.imread(\"testImages/%s\" % (imageName),1)\n",
    "# image = imutils.resize(image, width = 800)\n",
    "\n",
    "# faces=detector.detect_faces(image)\n",
    "\n",
    "# for i in range(len(faces)):\n",
    "#     x,y,w,h=faces[i]['box']\n",
    "#     sub_face = image[y:y + h, x:x + w,:]\n",
    "\n",
    "#     sub_face = cv2.resize(sub_face, (160, 160), interpolation = cv2.INTER_LINEAR)\n",
    "#     sub_face = sub_face / 255.\n",
    "#     sub_face = sub_face.reshape(1,160,160,3) \n",
    "\n",
    "#     captured_representation = classifier.predict(sub_face)[0,:]\n",
    "#     print('\\n',captured_representation,captured_representation.argmax(),person_dict[captured_representation.argmax()],'\\n')\n",
    "#     found = 0\n",
    "#     for i in all_people_faces:\n",
    "#         person_name = i\n",
    "#         representation = all_people_faces[i]\n",
    "#         similarity = findCosineSimilarity(representation, captured_representation)\n",
    "#         print(i,' similarity ',similarity)\n",
    "#         if(similarity < 0.05):\n",
    "#             cv2.putText(image, person_name, (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "#             found = 1\n",
    "#             break\n",
    "#     #connect face and text\n",
    "#     cv2.line(image,(int((x+x+w)/2),y+15),(x+w,y-20),(255, 0, 0),1)\n",
    "#     cv2.line(image,(x+w,y-20),(x+w+10,y-20),(255, 0, 0),1)\n",
    "\n",
    "#     if(found == 0): #if found image is not in our people database\n",
    "#         cv2.putText(image, 'unknown', (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "# cv2.imshow('frame', image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def preprocess_image(image_path):\n",
    "#     img = load_img(image_path, target_size=(160, 160))\n",
    "#     img = img_to_array(img)\n",
    "#     img = img / 255.\n",
    "#     img = img.reshape(1,160,160,3) \n",
    "#     return img\n",
    "\n",
    "# people_pictures = \"./persons/\"\n",
    "# imageName='xyz7.jpg'\n",
    "\n",
    "# all_people_faces = dict()\n",
    "\n",
    "# for file in listdir(people_pictures):\n",
    "#     person_face, extension = file.split(\".\")\n",
    "#     all_people_faces[person_face] = classifier.predict(preprocess_image('persons/%s.png' % (person_face)))[0,:]\n",
    "# #     print(person_face, all_people_faces[person_face])\n",
    "# #     all_people_faces[person_face] = classifier.predict(preprocess_image('persons/%s.png' % (person_face)))[0,:].argmax()\n",
    "# #     print(person_face,all_people_faces[person_face],person_dict[all_people_faces[person_face]])\n",
    "# print('------------------------------------------------------------------------------------------------')    \n",
    "\n",
    "# def findCosineSimilarity(source_representation, test_representation):\n",
    "#     a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "#     b = np.sum(np.multiply(source_representation, source_representation))\n",
    "#     c = np.sum(np.multiply(test_representation, test_representation))\n",
    "#     return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "\n",
    "\n",
    "# # image=cv2.imread(\"testImages/abca.jpg\",1)\n",
    "\n",
    "# for file in listdir('testImages'):\n",
    "#     print(file)\n",
    "\n",
    "#     image=cv2.imread('testImages/%s' % (file),1)\n",
    "#     image = imutils.resize(image, width = 800)\n",
    "\n",
    "#     faces=detector.detect_faces(image)\n",
    "\n",
    "#     for i in range(len(faces)):\n",
    "#         x,y,w,h=faces[i]['box']\n",
    "#         sub_face = image[y:y + h, x:x + w,:]\n",
    "\n",
    "#         sub_face = cv2.resize(sub_face, (160, 160), interpolation = cv2.INTER_LINEAR)\n",
    "#         sub_face = sub_face / 255.\n",
    "#         sub_face = sub_face.reshape(1,160,160,3) \n",
    "\n",
    "#         captured_representation = classifier.predict(sub_face)[0,:]\n",
    "#         print(captured_representation,captured_representation.argmax(),'\\n')\n",
    "#         found = 0\n",
    "#         for i in all_people_faces:\n",
    "#             person_name = i\n",
    "#     #         print(i, person_name)\n",
    "#             representation = all_people_faces[i]\n",
    "#             similarity = findCosineSimilarity(representation, captured_representation)\n",
    "#     #         print('similarity',similarity)\n",
    "#             if(similarity < 0.05):\n",
    "#                 cv2.putText(image, person_name, (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "#                 found = 1\n",
    "#                 break\n",
    "#         #connect face and text\n",
    "#         cv2.line(image,(int((x+x+w)/2),y+15),(x+w,y-20),(255, 0, 0),1)\n",
    "#         cv2.line(image,(x+w,y-20),(x+w+10,y-20),(255, 0, 0),1)\n",
    "\n",
    "#         if(found == 0): #if found image is not in our people database\n",
    "#             cv2.putText(image, 'unknown', (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "#     cv2.imshow('frame', image)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_image(image_path):\n",
    "#     img = load_img(image_path, target_size=(160, 160))\n",
    "#     img = img_to_array(img)\n",
    "#     img = img / 255.\n",
    "#     img = img.reshape(1,160,160,3) \n",
    "#     return img\n",
    "\n",
    "# people_pictures = \"./persons/\"\n",
    "\n",
    "# all_people_faces = dict()\n",
    "\n",
    "# for file in listdir(people_pictures):\n",
    "#     person_face, extension = file.split(\".\")\n",
    "#     all_people_faces[person_face] = classifier.predict(preprocess_image('persons/%s.png' % (person_face)))[0,:]\n",
    "# #     print(person_face, all_people_faces[person_face])\n",
    "# #     all_people_faces[person_face] = classifier.predict(preprocess_image('persons/%s.png' % (person_face)))[0,:].argmax()\n",
    "# #     print(person_face,all_people_faces[person_face],person_dict[all_people_faces[person_face]])\n",
    "# print('------------------------------------------------------------------------------------------------')    \n",
    "\n",
    "# def findCosineSimilarity(source_representation, test_representation):\n",
    "#     a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "#     b = np.sum(np.multiply(source_representation, source_representation))\n",
    "#     c = np.sum(np.multiply(test_representation, test_representation))\n",
    "#     return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "\n",
    "\n",
    "# image=cv2.imread(\"testImages/xyz3.jpg\",1)\n",
    "# image = imutils.resize(image, width = 800)\n",
    "\n",
    "# faces=detector.detect_faces(image)\n",
    "\n",
    "# for i in range(len(faces)):\n",
    "#     x,y,w,h=faces[i]['box']\n",
    "#     sub_face = image[y:y + h, x:x + w,:]\n",
    "\n",
    "#     sub_face = cv2.resize(sub_face, (160, 160), interpolation = cv2.INTER_LINEAR)\n",
    "#     sub_face = sub_face / 255.\n",
    "#     sub_face = sub_face.reshape(1,160,160,3) \n",
    "\n",
    "#     captured_representation = classifier.predict(sub_face)[0,:]\n",
    "#     found = 0\n",
    "#     person_name = person_dict[captured_representation.argmax()]\n",
    "#     person_name = person_name.lower()\n",
    "#     print(person_name)\n",
    "#     representation = all_people_faces[person_name]\n",
    "#     similarity = findCosineSimilarity(representation, captured_representation)\n",
    "#     print(person_name, (1-similarity)*100)\n",
    "#     if(similarity < 0.05):\n",
    "#         cv2.putText(image, person_name, (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "#         found = 1\n",
    "   \n",
    "    \n",
    "#     #connect face and text\n",
    "#     cv2.line(image,(int((x+x+w)/2),y+15),(x+w,y-20),(255, 0, 0),1)\n",
    "#     cv2.line(image,(x+w,y-20),(x+w+10,y-20),(255, 0, 0),1)\n",
    "\n",
    "#     if(found == 0): #if found image is not in our people database\n",
    "#         cv2.putText(image, 'unknown', (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "# cv2.imshow('frame', image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(160, 160))\n",
    "    img = img_to_array(img)\n",
    "    img = img / 255.\n",
    "    img = img.reshape(1,160,160,3) \n",
    "    return img\n",
    "\n",
    "people_pictures = \"./persons/\"\n",
    "\n",
    "all_people_faces = dict()\n",
    "\n",
    "for file in listdir(people_pictures):\n",
    "    person_face, extension = file.split(\".\")\n",
    "    all_people_faces[person_face] = classifier.predict(preprocess_image('persons/%s.png' % (person_face)))[0,:]\n",
    "#     print(person_face, all_people_faces[person_face])\n",
    "#     all_people_faces[person_face] = classifier.predict(preprocess_image('persons/%s.png' % (person_face)))[0,:].argmax()\n",
    "#     print(person_face,all_people_faces[person_face],person_dict[all_people_faces[person_face]])\n",
    "print('------------------------------------------------------------------------------------------------')    \n",
    "\n",
    "def findCosineSimilarity(source_representation, test_representation):\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "\n",
    "for file in listdir('testImages'):\n",
    "    print(file)\n",
    "    image=cv2.imread('testImages/%s' % (file),1)\n",
    "    image = imutils.resize(image, width = 600)\n",
    "#     image = cv2.resize(image, (0,0), fx=0.5, fy=0.5)\n",
    "\n",
    "    faces=detector.detect_faces(image)\n",
    "\n",
    "    for i in range(len(faces)):\n",
    "        x,y,w,h=faces[i]['box']\n",
    "        sub_face = image[y:y + h, x:x + w,:]\n",
    "\n",
    "        sub_face = cv2.resize(sub_face, (160, 160), interpolation = cv2.INTER_LINEAR)\n",
    "        sub_face = sub_face / 255.\n",
    "        sub_face = sub_face.reshape(1,160,160,3) \n",
    "\n",
    "        captured_representation = classifier.predict(sub_face)[0,:]\n",
    "        found = 0\n",
    "        person_name = person_dict[captured_representation.argmax()]\n",
    "        person_name = person_name.lower()\n",
    "        print(person_name)\n",
    "        representation = all_people_faces[person_name]\n",
    "        similarity = findCosineSimilarity(representation, captured_representation)\n",
    "        if(similarity < 0.15):\n",
    "            cv2.putText(image, person_name, (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            found = 1\n",
    "\n",
    "\n",
    "        #connect face and tex t\n",
    "        cv2.line(image,(int((x+x+w)/2),y+15),(x+w,y-20),(255, 0, 0),1)\n",
    "        cv2.line(image,(x+w,y-20),(x+w+10,y-20),(255, 0, 0),1)\n",
    "\n",
    "        if(found == 0): #if found image is not in our people database\n",
    "            cv2.putText(image, 'unknown', (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow('frame', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(160, 160))\n",
    "    img = img_to_array(img)\n",
    "    img = img / 255.\n",
    "    img = img.reshape(1,160,160,3) \n",
    "    return img\n",
    "\n",
    "people_pictures = \"./persons/\"\n",
    "\n",
    "all_people_faces = dict()\n",
    "\n",
    "for file in listdir(people_pictures):\n",
    "    person_face, extension = file.split(\".\")\n",
    "    all_people_faces[person_face] = classifier.predict(preprocess_image('persons/%s.png' % (person_face)))[0,:]\n",
    "#     print(person_face, all_people_faces[person_face])\n",
    "#     all_people_faces[person_face] = classifier.predict(preprocess_image('persons/%s.png' % (person_face)))[0,:].argmax()\n",
    "#     print(person_face,all_people_faces[person_face],person_dict[all_people_faces[person_face]])\n",
    "print('------------------------------------------------------------------------------------------------')    \n",
    "\n",
    "def findCosineSimilarity(source_representation, test_representation):\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "\n",
    "for file in listdir('testImages'):\n",
    "    print(file)\n",
    "    try:\n",
    "        image=cv2.imread('testImages/%s' % (file),1)\n",
    "    \n",
    "        image = imutils.resize(image, width = 600)\n",
    "    #     image = cv2.resize(image, (0,0), fx=0.5, fy=0.5)\n",
    "\n",
    "        faces=detector.detect_faces(image)\n",
    "\n",
    "        for i in range(len(faces)):\n",
    "            x,y,w,h=faces[i]['box']\n",
    "            sub_face = image[y:y + h, x:x + w,:]\n",
    "\n",
    "            sub_face = cv2.resize(sub_face, (160, 160), interpolation = cv2.INTER_LINEAR)\n",
    "            sub_face = sub_face / 255.\n",
    "            sub_face = sub_face.reshape(1,160,160,3) \n",
    "\n",
    "            captured_representation = classifier.predict(sub_face)[0,:]\n",
    "            found = 0\n",
    "            person_name = person_dict[captured_representation.argmax()]\n",
    "            person_name = person_name.lower()\n",
    "            print(person_name)\n",
    "            representation = all_people_faces[person_name]\n",
    "            similarity = findCosineSimilarity(representation, captured_representation)\n",
    "            if(similarity < 0.15):\n",
    "                cv2.putText(image, person_name, (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                found = 1\n",
    "\n",
    "\n",
    "            #connect face and tex t\n",
    "            cv2.line(image,(int((x+x+w)/2),y+15),(x+w,y-20),(255, 0, 0),1)\n",
    "            cv2.line(image,(x+w,y-20),(x+w+10,y-20),(255, 0, 0),1)\n",
    "\n",
    "            if(found == 0): #if found image is not in our people database\n",
    "                cv2.putText(image, 'unknown', (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        cv2.imshow('frame', image)\n",
    "    except (IOError, ValueError, IndexError) as e:\n",
    "        errorMessage = '{}: {}'.format(image_path, e)\n",
    "        print(errorMessage)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import imutils\n",
    "\n",
    "def getRandomImage(path):\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    final_path = file_path + \"/\" + image_name\n",
    "#     return image.load_img(final_path)\n",
    "    return cv2.imread(final_path)\n",
    "\n",
    "# predicting images\n",
    "for i in range(0, 10):\n",
    "    path = './data/val/'\n",
    "    image = getRandomImage(path)\n",
    "    image = imutils.resize(image, width = 800)\n",
    "    faces=detector.detect_faces(image)\n",
    "\n",
    "    for i in range(len(faces)):\n",
    "        x,y,w,h=faces[i]['box']\n",
    "        sub_face = image[y:y + h, x:x + w,:]\n",
    "\n",
    "        sub_face = cv2.resize(sub_face, (160, 160), interpolation = cv2.INTER_LINEAR)\n",
    "        sub_face = sub_face / 255.\n",
    "        sub_face = sub_face.reshape(1,160,160,3) \n",
    "\n",
    "        result = classifier.predict(sub_face, 1, verbose = 0).argmax()\n",
    "        person = person_dict[result]\n",
    "        print(person)\n",
    "\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(image, person, (x+ (w//2),y-2), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), lineType=cv2.LINE_AA)\n",
    "    cv2.imshow('frame', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "validation_data_dir = 'faces/val'\n",
    "batchSize=1000\n",
    "\n",
    "imageSize=160\n",
    "nb_train_samples = 92\n",
    "nb_validation_samples = 82\n",
    "\n",
    "step_size_validation=int(math.ceil(1.0 * nb_train_samples / batchSize))\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# We need to recreate our validation generator with shuffle = false\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(imageSize, imageSize),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "class_labels = validation_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "\n",
    "nb_train_samples = 93\n",
    "nb_validation_samples = 82\n",
    "\n",
    "#Confution Matrix and Classification Report\n",
    "Y_pred = classifier.predict_generator(validation_generator, step_size_validation)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = list(class_labels.values())\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "cnf_matrix = confusion_matrix(validation_generator.classes, y_pred)\n",
    "\n",
    "plt.imshow(cnf_matrix, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "_ = plt.xticks(tick_marks, classes, rotation=90)\n",
    "_ = plt.yticks(tick_marks, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "input_im=cv2.imread(\"testImages/abc1.jpg\")\n",
    "gray=cv2.cvtColor(input_im, cv2.COLOR_BGR2GRAY)\n",
    "# input_im = imutils.resize(input_im, width = 800)\n",
    "face_cascade = \"cascade files/haarcascade_frontalface_alt.xml\"\n",
    "# face_cascade = \"cascade files/haarcascade_frontalface_alt2.xml\"\n",
    "# face_cascade = \"cascade files/haarcascade_frontalface_default.xml\"\n",
    "cascade = cv2.CascadeClassifier(face_cascade)\n",
    "faces=cascade.detectMultiScale(gray,1.08,5)\n",
    "print(len(faces))\n",
    "print(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn.mtcnn import MTCNN\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier=load_model('model/12_facenet_keras1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir = 'faces/train'\n",
    "imageSize=160\n",
    "\n",
    "train_datagen=ImageDataGenerator( rescale=1./255,\n",
    "                                  rotation_range=45,\n",
    "                                  width_shift_range=0.3,\n",
    "                                  height_shift_range=0.3,\n",
    "                                  horizontal_flip=True,\n",
    "                                  fill_mode='nearest'\n",
    "                                ) \n",
    "train_generator=train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                  target_size=(imageSize,imageSize),\n",
    "                                                  color_mode='rgb',\n",
    "                                                  batch_size=32,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=True\n",
    "                                                  )\n",
    "\n",
    "\n",
    "class_labels = train_generator.class_indices\n",
    "person_dict = {v: k for k, v in class_labels.items()}\n",
    "classes = list(person_dict.values())\n",
    "print(person_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector=MTCNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread(\"testImages/abc1.jpg\")\n",
    "faces=detector.detect_faces(image)\n",
    "# print(detector.detect_faces(image))\n",
    "print(faces)\n",
    "# print(len(faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread(\"testImages/abc17.jpg\")\n",
    "faces=detector.detect_faces(image)\n",
    "\n",
    "for i in range(len(faces)):\n",
    "    x,y,w,h=faces[i]['box']\n",
    "    sub_face = image[y:y + h, x:x + w,:]\n",
    "\n",
    "    sub_face = cv2.resize(sub_face, (160, 160), interpolation = cv2.INTER_LINEAR)\n",
    "    sub_face = sub_face / 255.\n",
    "    sub_face = sub_face.reshape(1,160,160,3) \n",
    "\n",
    "    result = classifier.predict(sub_face, 1, verbose = 0).argmax()\n",
    "    person = person_dict[result]\n",
    "    print(person)\n",
    "    if(result>=0 or result<=len(person_dict)):\n",
    "        person = person_dict[result]\n",
    "        print(person)\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(image, person, (x+ (w//2),y-2), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), lineType=cv2.LINE_AA)\n",
    "    else:\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(image, 'unknown', (x+ (w//2),y-2), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), lineType=cv2.LINE_AA)\n",
    "cv2.imshow('frame', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face_cascade = r\"C:\\Users\\Amrender\\Downloads\\Realtime Face Recognition with DL Working\\haarcascade_frontalface_alt.xml\"\n",
    "# cascade = cv2.CascadeClassifier(face_cascade)\n",
    "detector=MTCNN()\n",
    "IMAGE_SIZE=160\n",
    "url='https://192.168.43.1:8080/video'\n",
    "camera = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    \n",
    "    ret, frame = camera.read()\n",
    "    frame = imutils.resize(frame, width = 800, height = 600)\n",
    "    \n",
    "    faces=detector.detect_faces(frame)\n",
    "\n",
    "    for i in range(len(faces)):\n",
    "        x,y,w,h=faces[i]['box']\n",
    "        sub_face = image[y:y + h, x:x + w,:]\n",
    "\n",
    "        sub_face = cv2.resize(sub_face, (160, 160), interpolation = cv2.INTER_LINEAR)\n",
    "        sub_face = sub_face / 255.\n",
    "        sub_face = sub_face.reshape(1,160,160,3) \n",
    "\n",
    "        result = classifier.predict(sub_face, 1, verbose = 0).argmax()\n",
    "        person = person_dict[result]\n",
    "        print(person)\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, person, (x+ (w//2),y-2), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), lineType=cv2.LINE_AA)\n",
    "\n",
    "    \n",
    "        cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from os import listdir\n",
    "from tensorflow.keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from tensorflow.python.keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Loads image from path and resizes it\"\"\"\n",
    "    img = load_img(image_path, target_size=(160, 160))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "people_pictures = \"./persons/\"\n",
    "\n",
    "all_people_faces = dict()\n",
    "\n",
    "for file in listdir(people_pictures):\n",
    "    person_face, extension = file.split(\".\")\n",
    "    all_people_faces[person_face] = classifier.predict(preprocess_image('./persons/%s.png' % (person_face)))[0,:]\n",
    "print(\"Face representations retrieved successfully\")\n",
    "\n",
    "def findCosineSimilarity(source_representation, test_representation):\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "\n",
    "detector=MTCNN()\n",
    "IMAGE_SIZE=160\n",
    "url='https://192.168.43.1:8080/video'\n",
    "camera = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    \n",
    "    ret, frame = camera.read()\n",
    "    frame = imutils.resize(frame, width = 800, height = 600)\n",
    "    \n",
    "    faces=detector.detect_faces(frame)\n",
    "\n",
    "    for i in range(len(faces)):\n",
    "        x,y,w,h=faces[i]['box']\n",
    "        sub_face = image[y:y + h, x:x + w,:]\n",
    "\n",
    "        sub_face = cv2.resize(sub_face, (160, 160), interpolation = cv2.INTER_LINEAR)\n",
    "        sub_face = sub_face / 255.\n",
    "        sub_face = sub_face.reshape(1,160,160,3) \n",
    "\n",
    "        captured_representation = classifier.predict(sub_face, 1, verbose = 0).argmax()\n",
    "        \n",
    "        found = 0\n",
    "        for i in all_people_faces:\n",
    "            person_name = i\n",
    "            representation = all_people_faces[i]\n",
    "            similarity = findCosineSimilarity(representation, captured_representation)\n",
    "            print(similarity,'\\n')\n",
    "            if(similarity < 0.50):\n",
    "                cv2.putText(input_im, person_name, (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "                found = 1\n",
    "                break\n",
    "        #connect face and text\n",
    "        cv2.line(input_im,(int((x+x+w)/2),y+15),(x+w,y-20),(255, 0, 0),1)\n",
    "        cv2.line(input_im,(x+w,y-20),(x+w+10,y-20),(255, 0, 0),1)\n",
    "\n",
    "        if(found == 0): #if found image is not in our people database\n",
    "            cv2.putText(input_im, 'unknown', (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        \n",
    "        cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread(\"testImages/abc1.jpg\")\n",
    "image = imutils.resize(image, width=800)\n",
    "faces=detector.detect_faces(image)\n",
    "\n",
    "for i in range(len(faces)):\n",
    "    x,y,w,h=faces[i]['box']\n",
    "    sub_face = image[y:y + h, x:x + w,:]\n",
    "\n",
    "    sub_face = cv2.resize(sub_face, (160, 160), interpolation = cv2.INTER_LINEAR)\n",
    "    sub_face = sub_face / 255.\n",
    "    sub_face = sub_face.reshape(1,160,160,3) \n",
    "\n",
    "    pred=classifier.predict(sub_face, 1, verbose = 0)\n",
    "    result = pred.argmax()\n",
    "    arr_result=[result]\n",
    "    \n",
    "    probablity=pred[np.arange(len(arr_result)), result]\n",
    "    print(probablity)\n",
    "    if(probablity>0.70):\n",
    "        person = person_dict[result]\n",
    "        print(person)\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(image, person, (x+ (w//2),y-2), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), lineType=cv2.LINE_AA)\n",
    "    else:\n",
    "        print('unknown')\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(image, 'unknown', (x+ (w//2),y-2), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), lineType=cv2.LINE_AA)\n",
    "cv2.imshow('frame', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from os import listdir\n",
    "from tensorflow.keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from tensorflow.python.keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Loads image from path and resizes it\"\"\"\n",
    "    img = load_img(image_path, target_size=(160, 160))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "people_pictures = \"./persons/\"\n",
    "\n",
    "all_people_faces = dict()\n",
    "\n",
    "for file in listdir(people_pictures):\n",
    "    person_face, extension = file.split(\".\")\n",
    "    all_people_faces[person_face] = classifier.predict(preprocess_image('./persons/%s.png' % (person_face)))[0,:]\n",
    "print(\"Face representations retrieved successfully\")\n",
    "\n",
    "def findCosineSimilarity(source_representation, test_representation):\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "\n",
    "input_im=cv2.imread(\"testImages/abc17.jpg\",1)\n",
    "input_im = imutils.resize(input_im, width = 800)\n",
    "face_cascade = \"haarcascade_frontalface_alt.xml\"\n",
    "cascade = cv2.CascadeClassifier(face_cascade)\n",
    "faces=cascade.detectMultiScale(input_im,1.3,5)\n",
    "\n",
    "for x,y,w,h in faces:\n",
    "    sub_face = input_im[y:y + h, x:x + w,:]\n",
    "    \n",
    "sub_face = cv2.resize(sub_face, (160, 160), interpolation = cv2.INTER_LINEAR)\n",
    "# sub_face.shape\n",
    "sub_face = sub_face / 255.\n",
    "# sub_face\n",
    "sub_face = sub_face.reshape(1,160,160,3) \n",
    "\n",
    "captured_representation = classifier.predict(sub_face)[0,:]\n",
    "found = 0\n",
    "for i in all_people_faces:\n",
    "    person_name = i\n",
    "    representation = all_people_faces[i]\n",
    "    similarity = findCosineSimilarity(representation, captured_representation)\n",
    "    print(similarity,'\\n')\n",
    "    if(similarity < 0.50):\n",
    "        cv2.putText(input_im, person_name, (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        found = 1\n",
    "        break\n",
    "#connect face and text\n",
    "cv2.line(input_im,(int((x+x+w)/2),y+15),(x+w,y-20),(255, 0, 0),1)\n",
    "cv2.line(input_im,(x+w,y-20),(x+w+10,y-20),(255, 0, 0),1)\n",
    "\n",
    "if(found == 0): #if found image is not in our people database\n",
    "    cv2.putText(input_im, 'unknown', (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('img',input_im)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#kill open cv things\n",
    "# cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "# # person = person_dict[result]\n",
    "# # print(person)\n",
    "\n",
    "# # result = np.argmax(classifier.predict(sub_face, 1, verbose = 0), axis=1)\n",
    "# # print(result)\n",
    "# # person = person_dict[str(result)]\n",
    "# # person\n",
    "\n",
    "# cv2.rectangle(input_im, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "# cv2.putText(input_im, person, (x+ (w//2),y-2), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), lineType=cv2.LINE_AA)\n",
    "# cv2.imshow('frame', input_im)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from os import listdir\n",
    "from tensorflow.keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from tensorflow.python.keras.applications.imagenet_utils import preprocess_input\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Loads image from path and resizes it\"\"\"\n",
    "    img = load_img(image_path, target_size=(160, 160))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "people_pictures = \"./persons/\"\n",
    "\n",
    "all_people_faces = dict()\n",
    "\n",
    "for file in listdir(people_pictures):\n",
    "    person_face, extension = file.split(\".\")\n",
    "    all_people_faces[person_face] = classifier.predict(preprocess_image('./persons/%s.png' % (person_face)))[0,:]\n",
    "print(\"Face representations retrieved successfully\")\n",
    "\n",
    "def findCosineSimilarity(source_representation, test_representation):\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "\n",
    "detector=MTCNN()\n",
    "input_im=cv2.imread(\"testImages/img.jpg\")\n",
    "input_im = imutils.resize(input_im, width=800)\n",
    "faces=detector.detect_faces(input_im)\n",
    "\n",
    "for i in range(len(faces)):\n",
    "    x,y,w,h=faces[i]['box']\n",
    "    sub_face = input_im[y:y + h, x:x + w,:]\n",
    "\n",
    "    sub_face = cv2.resize(sub_face, (160, 160), interpolation = cv2.INTER_LINEAR)\n",
    "    sub_face = sub_face / 255.\n",
    "    sub_face = sub_face.reshape(1,160,160,3) \n",
    "\n",
    "    captured_representation=classifier.predict(sub_face)[0]\n",
    "    \n",
    "    print(captured_representation)\n",
    "    \n",
    "#     found = 0\n",
    "    for j in all_people_faces:\n",
    "        person_name = j\n",
    "        representation = all_people_faces[j]\n",
    "        print(representation)\n",
    "        \n",
    "# #         print(captured_representation)\n",
    "#         similarity = findCosineSimilarity(representation, captured_representation)\n",
    "#         print(similarity,'\\n')\n",
    "#         if(similarity < 0.30):\n",
    "#             cv2.putText(input_im, person_name, (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            \n",
    "#     #connect face and text\n",
    "#             cv2.line(input_im,(int((x+x+w)/2),y+15),(x+w,y-20),(255, 0, 0),1)\n",
    "#             cv2.line(input_im,(x+w,y-20),(x+w+10,y-20),(255, 0, 0),1)\n",
    "\n",
    "#         else: #if found image is not in our people database\n",
    "#             cv2.putText(input_im, 'unknown', (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "\n",
    "#     cv2.imshow('frame', input_im)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
